{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7549487b6d70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7549487b78e0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranker/Desktop/Gen-AI/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.ypiyush.tech', 'title': 'Home | Piyush Yadav', 'description': 'Piyush Yadav is a full-stack developer in India. He is creative and passionate about design and technology so he always try to craft great-looking software products.', 'language': 'en-US'}, page_content='Home | Piyush YadavAboutGuestbookProjectsBlogContactSkip to main contentPiyush YadavStudent â€¢ Full-stack DeveloperI am a student and a Passionate and creative Full Stack developer based in India  ðŸ‡®ðŸ‡³SkillsNextJSReact NativeGolangJavascriptTypescriptHTML5CSS3TailwindCSSNodeJSMongoDBExpressJavaGraphQLGitPostgreSQLPrismaZustand/ RTKLinuxDockerTRPCFastAPIMySQLAzureJestRedisWork ExperienceCodemateSoftware Engineer - Full Stack Engineer - Oct 2023 - PresentLed the design and development of full-stack services for the Tech Innovation Group, enhancing system functionality and reliability using Next.js, Node.js, Langchain, Flask, Azure and Redis.Designed and implemented user-friendly dashboards, integrating front-end interfaces with Generative AI models and ensuring seamless back-end functionality, driving substantial user engagement and satisfaction.Collaborated with cross-functional teams to gather system requirements, balance workloads, and oversee the end-to-end software development lifecycle from implementation to deployment.Established robust CI/CD pipelines, conducted pull requests, and performed code reviews, ensuring high standards of code quality, scalability, and maintainability through rigorous testing (unit, integration, and end-to-end testing).One OathFull Stack Developer Intern - June 2023 - Oct 2023Spearheaded the development of microservices using Node.js, Python, Open AI for the clientâ€™s personality development system.Developed a CI/CD workflow to automatically perform a set of actions daily on a product in development in order to decrease time needed for team members to identify and fix bugs/issues.Collaborated closely with the AI core team to strategically integrate Python backend components, ensuring the seamless operation of critical system functions.AAA Intergalactic â€“ InfrastructureWeb Developer Intern - March 2023 - June 2023Orchestrated the creation of static websites for clients, accompanied by the development of microservices for seamless website operationPlayed a pivotal role in shaping architecture plans, UI designs, and feature development, contributing to a 15% increase in project success rateDrove the development of static websites and streamlined microservices, leading to a remarkable 20% decrease in project timelinesLoading ...HomeAboutBlogContactGuestbookGoalsProjectsExperienceLinkedInInstagramGitHubMediumÂ© 2024 PiyushYour info')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://www.ypiyush.tech\"),\n",
    "    # bs_kwargs=dict(parse_only=bs4.SoupStrainer(\"p\"))\n",
    ")\n",
    "docs= loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7549495bffa0>, search_kwargs={})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits=text_splitter.split_documents(docs)\n",
    "vector_store=Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt= (\n",
    "    \"You are an assistant for question -answering tasks\"\n",
    "    \"Use the following peices of retreived context to answer\"\n",
    "    \"the question. if you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentaces maximum and keep the \"\n",
    "    \"answer concise\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "response =rag_chain.invoke({\"input\": \"Who is Piyush Yadav?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Piyush Yadav is a full-stack developer in India. He is creative and passionate about design and technology so he always try to craft great-looking software products.', 'language': 'en-US', 'source': 'https://www.ypiyush.tech', 'title': 'Home | Piyush Yadav'}, page_content='Home | Piyush YadavAboutGuestbookProjectsBlogContactSkip to main contentPiyush YadavStudent â€¢ Full-stack DeveloperI am a student and a Passionate and creative Full Stack developer based in India  ðŸ‡®ðŸ‡³SkillsNextJSReact NativeGolangJavascriptTypescriptHTML5CSS3TailwindCSSNodeJSMongoDBExpressJavaGraphQLGitPostgreSQLPrismaZustand/ RTKLinuxDockerTRPCFastAPIMySQLAzureJestRedisWork ExperienceCodemateSoftware Engineer - Full Stack Engineer - Oct 2023 - PresentLed the design and development of full-stack services for the Tech Innovation Group, enhancing system functionality and reliability using Next.js, Node.js, Langchain, Flask, Azure and Redis.Designed and implemented user-friendly dashboards, integrating front-end interfaces with Generative AI models and ensuring seamless back-end functionality, driving substantial user engagement and satisfaction.Collaborated with cross-functional teams to gather system requirements, balance workloads, and oversee the end-to-end software development'),\n",
       " Document(metadata={'source': 'https://ypiyush.tech'}, page_content='I am a student and a Passionate and creative Full Stack developer based in India  ðŸ‡®ðŸ‡³Software Engineer - Full Stack Engineer - Oct 2023 - PresentFull Stack Developer Intern - June 2023 - Oct 2023Web Developer Intern - March 2023 - June 2023Loading ...'),\n",
       " Document(metadata={'source': 'https://ypiyush.tech'}, page_content='I am a student and a Passionate and creative Full Stack developer based in India  ðŸ‡®ðŸ‡³Software Engineer - Full Stack Engineer - Oct 2023 - PresentFull Stack Developer Intern - June 2023 - Oct 2023Web Developer Intern - March 2023 - June 2023Loading ...'),\n",
       " Document(metadata={'source': 'https://ypiyush.tech'}, page_content='I am a student and a Passionate and creative Full Stack developer based in India  ðŸ‡®ðŸ‡³Software Engineer - Full Stack Engineer - Oct 2023 - PresentFull Stack Developer Intern - June 2023 - Oct 2023Web Developer Intern - March 2023 - June 2023Loading ...')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"context\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addhing Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "contextualize_system_prompt = (\n",
    "    \"given a chat history and the latest user question\"\n",
    "    \"which might reference context in the chat history\"\n",
    "    \"formulate a standalone question which can be understood\"\n",
    "    \"without the chat history. Do NOT answer the question,\"\n",
    "    \"just reformulate it if needed and otherwise return as as is. \"\n",
    ")\n",
    "contextulaize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7549495bffa0>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x754a54072c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='given a chat history and the latest user questionwhich might reference context in the chat historyformulate a standalone question which can be understoodwithout the chat history. Do NOT answer the question,just reformulate it if needed and otherwise return as as is. '), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7549487b6d70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7549487b78e0>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7549495bffa0>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retreiver= create_history_aware_retriever(llm, retriever, contextulaize_q_prompt)\n",
    "history_aware_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retreiver, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piyush Yadav is based in India.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "chat_history = []\n",
    "question=\"who is Piyush yadav?\"\n",
    "response1= rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response1[\"answer\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2=\"Piyush is from which country?\"\n",
    "response2=rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='who is Piyush yadav?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Piyush Yadav is a student and a passionate full-stack developer based in India.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "conversation_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked for information about a student and a Passionate and creative Full Stack developer based in India.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_rag_chain.invoke(\n",
    "        {\"input\": \"Who is Piyush Yadav and where he is from?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"piyush123\"}},\n",
    " )[\"answer\"]\n",
    "\n",
    "conversation_rag_chain.invoke(\n",
    "        {\"input\": \"whose information i asked before?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"piyush123\"}},\n",
    " )[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
