{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5o1_nQv9KKe",
        "outputId": "1b9361eb-1fc7-4aaf-e283-f5ea3392c5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/471.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m471.0/471.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q cassio langchain openai tiktoken langchain_community datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D36yzwrx91mj"
      },
      "source": [
        "import the pakcaged we will need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n3rvJXbM9izh"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OpsAksqR_MqH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# with cassio, engine poewring astra db integration in langchain. initalize the db connection\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVLLK3kY_00J"
      },
      "outputs": [],
      "source": [
        "!pip install pyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oiAleuuU__Vo"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqqjLzvXAQG_"
      },
      "source": [
        "adding astra db coonection details and open ai key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nTZkh29oALeI"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN=\"\"\n",
        "ASTRA_DB_ID=\"\"\n",
        "\n",
        "OPENAI_API_KEY=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EwaI8AZZA2GB"
      },
      "outputs": [],
      "source": [
        "pdfreader = PdfReader(\"resume.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yjfPrVy2BUYz"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text=\"\"\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV-qKrXgB2an"
      },
      "outputs": [],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eTSFXdjqB9_9"
      },
      "outputs": [],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCEZc8AXCUuZ",
        "outputId": "02b259a1-7039-4694-eb74-9695c35ad7f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-799b35011f84>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bC16vy1xCqZb"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QvZwIiZeDMWq"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embeddings,\n",
        "    table_name=\"resume\",\n",
        "    session=None,\n",
        "    keyspace=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tHH9hgUiDnA9"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\",chunk_size=800, chunk_overlap=200, length_function=len)\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "utEtPZtPEHKX",
        "outputId": "9fef0b32-3e3c-4e4f-9fb7-39675801dd1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Piyush Yadav\\nBhopal, Madhya Pradesh, India, 462008\\n♂phone+91 8827413831 /envel⌢pepiyushyadav0191@gmail.com /linkedinlinkedin.com/in/piyushyadav0191 /product-huntPortfolio\\nEducation\\nBarkatullah University Institute of Technology [BUIT] Nov. 2020 – June 2024\\nBachelor of Technology in Information Technology Bhopal, Madhya Pradesh\\nExperience\\nCodemate AI Sep 2023 – Sep 2024\\nSDE - I - Full Stack Noida, UP\\n•Designed and implemented full-stack services using Next.Js, Node.js, Flask, and Azure, enhancing the functionality and\\nreliability of the system.\\n•Collaborated with cross-functional teams to create a user-friendly dashboard, integrating front-end with Generative AI\\nModels and ensuring seamless back-end functionality.',\n",
              " 'reliability of the system.\\n•Collaborated with cross-functional teams to create a user-friendly dashboard, integrating front-end with Generative AI\\nModels and ensuring seamless back-end functionality.\\n•Conducted regular code reviews, providing constructive feedback to maintain high code quality standards, and ensuring\\nscalability and maintainability.\\nOne Oath June 2023 – Aug 2023\\nFull Stack Developer Intern West Bengal, India (Remote)\\n•Spearheaded the development of microservices and user interface components, resulting in a 30% increase in user\\nengagement for the client’s personality development system.\\n•Developed a CI/CD workflow to automatically perform a set of actions daily on a product in development in order to\\ndecrease time needed for team members to identify and fix bugs/issues.',\n",
              " '•Developed a CI/CD workflow to automatically perform a set of actions daily on a product in development in order to\\ndecrease time needed for team members to identify and fix bugs/issues.\\n•Collaborated closely with the AI core team to strategically integrate Python backend components, ensuring the seamless\\noperation of critical system functions.\\nAAA Intergalactic – Infrastructure March 2023 – May 2023\\nWeb Developer Cameroon, Africa (Remote)\\n•Orchestrated the creation of static websites for clients, accompanied by the development of microservices for seamless\\nwebsite operation.\\n•Played a pivotal role in shaping architecture plans, UI designs, and feature development, contributing to a 15% increase\\nin project success rate.\\nProjects',\n",
              " 'website operation.\\n•Played a pivotal role in shaping architecture plans, UI designs, and feature development, contributing to a 15% increase\\nin project success rate.\\nProjects\\nResearch Paper’s Decoder |Nextjs, Typescript, Node, Docker, langchain, Supabase, Unstructured, Open AI /github\\n•Developed a Full Stack project, Research PDF Decoder, emphasizing the extraction of key insights from research papers\\nPDFs and enabling interactive dialogue with PDF content.\\n•Utilized a robust tech stack including Next.js, TypeScript, Node.js, Docker, Langchain, Supabase, Unstructured, and\\nOpenAI to ensure seamless functionality and efficient data processing.\\nQuesGen Pro |Nextjs, Typescript, Nodejs, Prisma, Docker, PostgreSQL, OpenAI, GDC, GraphQL, Sanity, Framer /github',\n",
              " 'OpenAI to ensure seamless functionality and efficient data processing.\\nQuesGen Pro |Nextjs, Typescript, Nodejs, Prisma, Docker, PostgreSQL, OpenAI, GDC, GraphQL, Sanity, Framer /github\\n•Designed and implemented a test-taking platform with AI-generated questions, resulting in a 40% increase in user\\nengagement.\\n•Utilized OpenAI to dynamically generate questions, enhancing test variety and engagement.\\nTechnical Skills\\nProgramming Languages: : Javascript/ Typescript, Python, Golang(Basic), SQL\\nWeb Development Technologies: : HTML, Css, Reactjs/Nextjs, Nodejs\\nBackend Technologies: : GraphQL, Nodejs, Express, FastAPI, TRPC, NestJS(Basic)\\nFull Stack Technologies: : MERN, Nextjs + Prisma + PSQL, TRPC, MERN+GraphQL\\nApp Development Technologies: : React Native, Firebase, Nodejs',\n",
              " 'Full Stack Technologies: : MERN, Nextjs + Prisma + PSQL, TRPC, MERN+GraphQL\\nApp Development Technologies: : React Native, Firebase, Nodejs\\nAI/ML: : Langchain, OpenAI, Jupytor Notebook, Datastax\\nDeveloper Tools: : Git, Docker, Azure, AWS, Open AI, Vs Code, Github Actions, Datastax, Upstash\\nExtracurricular activities\\n•Contributed to an open-source project by creating a pull request for one of the REST APIs within the Postman Labs\\nGitHub repository.\\n•Achieved a ranking of AIR 44 in Codekaze 2023, earning an internship offer and the opportunity to collaborate with the\\nCoding Ninja team and community.\\n•Regularly share technical knowledge through blog posts on various topics. You can find my articles on /medium.']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0d-EFNiEQPf",
        "outputId": "ea3f90e5-1c7d-4bb7-9f9b-bcdb7bde3626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 6 headlines\n"
          ]
        }
      ],
      "source": [
        "astra_vector_store.add_texts(texts[:50])\n",
        "print(\"Inserted %i headlines\"% len(texts[:50]))\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "C9yA3VVDE-s1",
        "outputId": "4c9fa5b4-3e38-4ae8-e884-227e5a7ce9ee"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5a68bc831b63>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfirst_question\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Enter your questionn \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mquery_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Whats your next question\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text = input(\"\\n Enter your questionn \\n\").strip()\n",
        "  else:\n",
        "    query_text= input(\"\\n Whats your next question\")\n",
        "\n",
        "  if query_text.lower() == 'quit':\n",
        "    break\n",
        "  if query_text == \"\":\n",
        "    continue\n",
        "\n",
        "  first_question = False\n",
        "\n",
        "  print(\"\\n Question: \\\"%s\\\"\" % query_text)\n",
        "  answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "  print(\"Answer: \\\"%s\\\"\" % answer)\n",
        "\n",
        "  print(\"First documents by RELEVANCE\")\n",
        "  for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "    print(\"    [%0.4f] \\\"%s\\\"\" % (score, doc.page_content[:84]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZwgZnreF5lB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
